{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HipHopPopModeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqlQYZpw8kp6"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.random import set_seed\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPJ-qaBcpZO0"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qlZgAcC6T6c"
      },
      "source": [
        "# Defining a results visualization function\n",
        "def visualize_training_results(history):\n",
        "    '''\n",
        "    From https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
        "    \n",
        "    Input: keras history object (output from trained model)\n",
        "    '''\n",
        "    fig, (ax1, ax2) = plt.subplots(2, figsize=(8,8), sharex=True)\n",
        "    fig.suptitle('Model Results')\n",
        "\n",
        "    # summarize history for accuracy\n",
        "    ax1.plot(history.history['accuracy'])\n",
        "    ax1.plot(history.history['val_accuracy'])\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend(['train', 'test'], loc='upper left')\n",
        "    # summarize history for loss\n",
        "    ax2.plot(history.history['loss'])\n",
        "    ax2.plot(history.history['val_loss'])\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend(['train', 'test'], loc='upper left')\n",
        "    \n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LaiIjQbdV1w"
      },
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/mel_spec_sc.pkl', 'rb') as up:\n",
        "    mel_spec_sc = pickle.load(up)\n",
        "X_train, y_train = mel_spec_sc['X_train'][0], mel_spec_sc['X_train'][1]\n",
        "X_test, y_test = mel_spec_sc['X_test'][0], mel_spec_sc['X_test'][1]\n",
        "X_holdout, y_holdout = mel_spec_sc['X_holdout'][0], mel_spec_sc['X_holdout'][1]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjMwbGnRe2gZ"
      },
      "source": [
        "### First Model - Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpMQ8X4UfKnC"
      },
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "batch_size = X_train.shape[0]/100"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UbwyFyLiezii",
        "outputId": "ab6acd07-f8e5-4498-bcb2-297debd3d910"
      },
      "source": [
        "input_shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 1292, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiHLig1qezeE",
        "outputId": "ad44984e-d38a-4907-dc78-f3197aa01d3c"
      },
      "source": [
        "# set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "set_seed(42)\n",
        "\n",
        "# build sequentially\n",
        "mlp = keras.Sequential(name='mlp')\n",
        "\n",
        "# flatten input 3D tensor to 1D\n",
        "mlp.add(layers.Flatten(input_shape=input_shape))\n",
        "\n",
        "# two hidden layers\n",
        "mlp.add(layers.Dense(128, activation='relu'))\n",
        "mlp.add(layers.Dense(64, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "mlp.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile cnn\n",
        "mlp.compile(loss='binary_crossentropy',\n",
        "            optimizer=\"adam\",\n",
        "            metrics=['accuracy', 'Recall'])\n",
        "\n",
        "# take a look at model architecture\n",
        "mlp.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mlp\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 165376)            0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               21168256  \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,176,577\n",
            "Trainable params: 21,176,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUT7EX3efADQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d6056f-b553-488f-ecfd-0f2e439e6590"
      },
      "source": [
        "fsm_history = mlp.fit(X_train, y_train, epochs=60, batch_size=30,\n",
        "                  validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "346/346 [==============================] - 15s 39ms/step - loss: 2.5842 - accuracy: 0.4952 - recall: 0.4904 - val_loss: 1.5612 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.8632 - accuracy: 0.4939 - recall: 0.4727 - val_loss: 0.7065 - val_accuracy: 0.4885 - val_recall: 0.9991\n",
            "Epoch 3/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.7371 - accuracy: 0.5040 - recall: 0.4894 - val_loss: 0.7026 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 4/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.7106 - accuracy: 0.5095 - recall: 0.4975 - val_loss: 0.6937 - val_accuracy: 0.4893 - val_recall: 0.9991\n",
            "Epoch 5/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.7029 - accuracy: 0.4978 - recall: 0.4389 - val_loss: 0.6921 - val_accuracy: 0.5227 - val_recall: 0.9157\n",
            "Epoch 6/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.7130 - accuracy: 0.5184 - recall: 0.1660 - val_loss: 0.6926 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 7/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 8/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 9/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 10/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 11/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 12/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 13/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 14/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6928 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 15/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 16/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 17/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 18/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6926 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 19/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6929 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 20/60\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6928 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 21/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6926 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 22/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 23/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 24/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6928 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 25/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 26/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6928 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 27/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6926 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 28/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 29/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5078 - recall: 0.0349 - val_loss: 0.6926 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 30/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 31/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 32/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6928 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 33/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 34/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 35/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 36/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 37/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6930 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 38/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 39/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 40/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 41/60\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 42/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 43/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 44/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6926 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 45/60\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 46/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6926 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 47/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6926 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 48/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 49/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 50/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 51/60\n",
            "346/346 [==============================] - 18s 53ms/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6926 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 52/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 53/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6928 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 54/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 55/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 56/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 57/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 58/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 59/60\n",
            "346/346 [==============================] - 14s 41ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 60/60\n",
            "346/346 [==============================] - 14s 40ms/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6926 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "Gf8K_PeStClz",
        "outputId": "fe7c3898-6e0a-4b98-85ca-2fe752c9623a"
      },
      "source": [
        "visualize_training_results(fsm_history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnD7e_mVZ08D"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g0_N4vb6Y0t",
        "outputId": "96e646b6-2398-473f-993b-9adeac230869"
      },
      "source": [
        "# set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "set_seed(42)\n",
        "\n",
        "# build sequentially\n",
        "cnn1 = keras.Sequential(name='cnn1')\n",
        "\n",
        "# convolutional and max pooling layers with successively more filters\n",
        "cnn1.add(layers.Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "cnn1.add(layers.MaxPooling2D((2, 4)))\n",
        "\n",
        "cnn1.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "cnn1.add(layers.MaxPooling2D((2, 4)))\n",
        "\n",
        "cnn1.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "cnn1.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "cnn1.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "cnn1.add(layers.MaxPool2D((2, 2)))\n",
        "\n",
        "# fully-connected layers for output\n",
        "cnn1.add(layers.Flatten())\n",
        "cnn1.add(layers.Dense(128, activation='relu'))\n",
        "cnn1.add(layers.Dropout(0.3))\n",
        "cnn1.add(layers.Dense(64, activation='relu'))\n",
        "cnn1.add(layers.Dropout(0.3))\n",
        "\n",
        "# output layer\n",
        "cnn1.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile cnn\n",
        "cnn1.compile(loss='binary_crossentropy',\n",
        "            optimizer=\"adam\",\n",
        "            metrics=['accuracy', 'Recall'])\n",
        "\n",
        "# take a look at model architecture\n",
        "cnn1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cnn1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 128, 1292, 16)     160       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 64, 323, 16)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 64, 323, 32)       4640      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 32, 80, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 32, 80, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 16, 40, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 16, 40, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 8, 20, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 20480)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               2621568   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,718,849\n",
            "Trainable params: 2,718,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "Dr1_bA12G1ws",
        "outputId": "175ca246-f195-4a15-dab0-97cf717efda0"
      },
      "source": [
        "cnn1_history = cnn1.fit(X_train, y_train, epochs=60, batch_size=100,\n",
        "                  validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "104/104 [==============================] - 191s 2s/step - loss: 0.6937 - accuracy: 0.5081 - recall: 0.0949 - val_loss: 0.6926 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 2/60\n",
            "104/104 [==============================] - 190s 2s/step - loss: 0.6930 - accuracy: 0.5074 - recall: 0.0497 - val_loss: 0.6929 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 3/60\n",
            "104/104 [==============================] - 177s 2s/step - loss: 0.6932 - accuracy: 0.5114 - recall: 0.0026 - val_loss: 0.6928 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 4/60\n",
            "104/104 [==============================] - 166s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 7.8942e-04 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 5/60\n",
            "104/104 [==============================] - 162s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 6/60\n",
            "104/104 [==============================] - 162s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 1.9736e-04 - val_loss: 0.6926 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 7/60\n",
            "104/104 [==============================] - 162s 2s/step - loss: 0.6928 - accuracy: 0.5111 - recall: 0.0085 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 8/60\n",
            "104/104 [==============================] - 162s 2s/step - loss: 0.6929 - accuracy: 0.5120 - recall: 0.0600 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 9/60\n",
            "104/104 [==============================] - 163s 2s/step - loss: 0.6930 - accuracy: 0.5114 - recall: 0.0020 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 10/60\n",
            " 99/104 [===========================>..] - ETA: 7s - loss: 0.6930 - accuracy: 0.5120 - recall: 0.0079"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8f1da1d9560f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m cnn1_history = cnn1.fit(X_train, y_train, epochs=60, batch_size=100,\n\u001b[0;32m----> 2\u001b[0;31m                   validation_data=(X_test, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWgWwi33Pkfe",
        "outputId": "bc9bd186-622c-4f62-986d-0d27630d54f3"
      },
      "source": [
        "# set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "set_seed(42)\n",
        "\n",
        "# build sequentially\n",
        "cnn2 = keras.Sequential(name='cnn2')\n",
        "\n",
        "# convolutional and max pooling layers with successively more filters\n",
        "cnn2.add(layers.Conv2D(32, (2, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "cnn2.add(layers.MaxPooling2D((2, 4)))\n",
        "\n",
        "cnn2.add(layers.Conv2D(64, (2, 3), activation='relu', padding='same'))\n",
        "cnn2.add(layers.MaxPooling2D((2, 4)))\n",
        "\n",
        "cnn2.add(layers.Conv2D(128, (2, 3), activation='relu', padding='same'))\n",
        "cnn2.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "cnn2.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "cnn2.add(layers.MaxPool2D((2, 2)))\n",
        "\n",
        "# fully-connected layers for output\n",
        "cnn2.add(layers.Flatten())\n",
        "cnn2.add(layers.Dense(128, activation='relu'))\n",
        "# cnn2.add(layers.Dropout(0.3))\n",
        "# cnn2.add(layers.Dense(64, activation='relu'))\n",
        "# cnn2.add(layers.Dropout(0.3))\n",
        "\n",
        "# output layer\n",
        "cnn2.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile cnn\n",
        "cnn2.compile(loss='binary_crossentropy',\n",
        "            optimizer=\"adam\",\n",
        "            metrics=['accuracy', 'Recall'])\n",
        "\n",
        "# take a look at model architecture\n",
        "cnn2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cnn2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 128, 1292, 32)     224       \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 64, 323, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 64, 323, 64)       12352     \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 32, 80, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 32, 80, 128)       49280     \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 16, 40, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 16, 40, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 8, 20, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 20480)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               2621568   \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,831,137\n",
            "Trainable params: 2,831,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "CrU4pAQjQyGY",
        "outputId": "eb0b4691-87da-41cc-b778-3203c64d1866"
      },
      "source": [
        "cnn2_history = cnn2.fit(X_train, y_train, epochs=60, batch_size=100,\n",
        "                  validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 51/104 [=============>................] - ETA: 1:52 - loss: 0.4188 - accuracy: 0.7971 - recall: 0.8107"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d879ba0f8fca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m cnn2_history = cnn2.fit(X_train, y_train, epochs=60, batch_size=100,\n\u001b[0;32m----> 2\u001b[0;31m                   validation_data=(X_test, y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "TEcuhL8A5lVM",
        "outputId": "218884c9-40f9-4587-b1fd-7e5ddf55ad8a"
      },
      "source": [
        "visualize_training_results(cnn2_history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-432aea3ed17f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_training_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn2_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn2_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "lvAUEzB5Raqe",
        "outputId": "9a0e912b-e1ca-4bc9-8569-5ae9acb61eeb"
      },
      "source": [
        "# set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "set_seed(42)\n",
        "\n",
        "# build sequentially\n",
        "cnn3 = keras.Sequential(name='cnn3')\n",
        "\n",
        "# convolutional and max pooling layers with successively more filters\n",
        "cnn3.add(layers.Conv2D(32, (2, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "cnn3.add(layers.MaxPooling2D((2, 4)))\n",
        "\n",
        "cnn3.add(layers.Conv2D(64, (2, 3), activation='relu', padding='same'))\n",
        "cnn3.add(layers.MaxPooling2D((2, 4)))\n",
        "\n",
        "cnn3.add(layers.Conv2D(128, (2, 3), activation='relu', padding='same'))\n",
        "cnn3.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "cnn3.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "cnn3.add(layers.MaxPool2D((2, 2)))\n",
        "\n",
        "# fully-connected layers for output\n",
        "cnn3.add(layers.Flatten())\n",
        "cnn3.add(layers.Dense(128, activation='relu'))\n",
        "cnn3.add(layers.Dropout(0.3))\n",
        "cnn3.add(layers.Dense(64, activation='relu'))\n",
        "cnn3.add(layers.Dropout(0.3))\n",
        "\n",
        "# output layer\n",
        "cnn3.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile cnn\n",
        "cnn3.compile(loss='binary_crossentropy',\n",
        "            optimizer=\"adam\",\n",
        "            metrics=['accuracy', 'Recall'])\n",
        "\n",
        "# take a look at model architecture\n",
        "cnn3.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-077e7b87db1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# set random seed for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# build sequentially\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eOUkqxSineJn",
        "outputId": "374c5f6d-e9fb-41b0-d0b1-4a53fa4f98e6"
      },
      "source": [
        "cnn3_history = cnn3.fit(X_train, y_train, epochs=120, batch_size=100,\n",
        "                  validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "104/104 [==============================] - 235s 2s/step - loss: 0.6933 - accuracy: 0.5073 - recall: 0.2368 - val_loss: 0.6938 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 2/120\n",
            "104/104 [==============================] - 239s 2s/step - loss: 0.6930 - accuracy: 0.5070 - recall: 0.0967 - val_loss: 0.6932 - val_accuracy: 0.4839 - val_recall: 1.0000\n",
            "Epoch 3/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6933 - accuracy: 0.5126 - recall: 0.0857 - val_loss: 0.6928 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 4/120\n",
            "104/104 [==============================] - 230s 2s/step - loss: 0.6931 - accuracy: 0.5116 - recall: 0.0020 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 5/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5115 - recall: 0.0022 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 6/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6930 - accuracy: 0.5116 - recall: 0.0154 - val_loss: 0.6926 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 7/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6930 - accuracy: 0.5111 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 8/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6930 - accuracy: 0.5108 - recall: 0.0016 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 9/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6931 - accuracy: 0.5110 - recall: 0.0014 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 10/120\n",
            "104/104 [==============================] - 238s 2s/step - loss: 0.6930 - accuracy: 0.5111 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 11/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5113 - recall: 1.9736e-04 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 12/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 13/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 14/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 15/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 16/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 17/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 18/120\n",
            "104/104 [==============================] - 235s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 19/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6928 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 20/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 21/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 22/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 23/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 24/120\n",
            "104/104 [==============================] - 238s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 25/120\n",
            "104/104 [==============================] - 234s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 26/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 27/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 28/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 29/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 30/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 31/120\n",
            "104/104 [==============================] - 234s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 32/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 33/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 34/120\n",
            "104/104 [==============================] - 230s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 35/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 36/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 37/120\n",
            "104/104 [==============================] - 237s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 38/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 39/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 40/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 41/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6930 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 42/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 43/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 44/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 45/120\n",
            "104/104 [==============================] - 235s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 46/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 47/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 48/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 49/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 50/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 51/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 52/120\n",
            "104/104 [==============================] - 237s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 53/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 54/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 55/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 56/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 57/120\n",
            "104/104 [==============================] - 230s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 58/120\n",
            "104/104 [==============================] - 230s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 59/120\n",
            "104/104 [==============================] - 235s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 60/120\n",
            "104/104 [==============================] - 234s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 61/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 62/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 63/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 64/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 65/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 66/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 67/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 68/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 69/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 70/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 71/120\n",
            "104/104 [==============================] - 235s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 72/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 73/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 74/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 75/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 76/120\n",
            "104/104 [==============================] - 235s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 77/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 78/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 79/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 80/120\n",
            "104/104 [==============================] - 234s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 81/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 82/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 83/120\n",
            "104/104 [==============================] - 233s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 84/120\n",
            "104/104 [==============================] - 235s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 85/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 86/120\n",
            "104/104 [==============================] - 241s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 87/120\n",
            "104/104 [==============================] - 234s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 88/120\n",
            "104/104 [==============================] - 232s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 89/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 90/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 91/120\n",
            "104/104 [==============================] - 236s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 92/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 93/120\n",
            "104/104 [==============================] - 231s 2s/step - loss: 0.6929 - accuracy: 0.5112 - recall: 0.0000e+00 - val_loss: 0.6927 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 94/120\n",
            " 81/104 [======================>.......] - ETA: 49s - loss: 0.6930 - accuracy: 0.5102 - recall: 0.0000e+00"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8PgU7VS6gYL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "67d322cb-7861-4488-f38b-9000a9d4b6b7"
      },
      "source": [
        "visualize_training_results(cnn3_history)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1042fd1f3ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_training_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn3_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn3_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yor1GpofZ7oe"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkEJltNR6pU3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b4172121-422b-42a1-fb5c-1eed84df9655"
      },
      "source": [
        "# set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "set_seed(42)\n",
        "\n",
        "# build sequentially\n",
        "rnn = keras.Sequential(name='rnn')\n",
        "\n",
        "# convolutional and max pooling layers with successively more filters\n",
        "rnn.add(layers.Conv2D(64, (3, 3), activation='elu', padding='same', input_shape=(128, 1292, 1)))\n",
        "rnn.add(layers.MaxPooling2D((2, 2)))\n",
        "rnn.add(layers.Dropout(0.1))\n",
        "\n",
        "rnn.add(layers.Conv2D(128, (3, 3), activation='elu', padding='same'))\n",
        "rnn.add(layers.MaxPooling2D((4, 2)))\n",
        "rnn.add(layers.Dropout(0.1))\n",
        "\n",
        "rnn.add(layers.Conv2D(128, (3, 3), activation='elu', padding='same'))\n",
        "rnn.add(layers.MaxPooling2D((4, 2)))\n",
        "rnn.add(layers.Dropout(0.1))\n",
        "\n",
        "rnn.add(layers.Conv2D(128, (3, 3), activation='elu', padding='same'))\n",
        "rnn.add(layers.MaxPool2D((4, 2)))\n",
        "rnn.add(layers.Dropout(0.1))\n",
        "\n",
        "rnn.add(layers.Reshape((80,128)))\n",
        "rnn.add(layers.GRU(units=32, dropout=0.3, return_sequences=True))\n",
        "rnn.add(layers.GRU(units=32, dropout=0.3))\n",
        "\n",
        "# output layer\n",
        "rnn.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile cnn\n",
        "rnn.compile(loss='binary_crossentropy',\n",
        "            optimizer=\"adam\", \n",
        "            metrics=['accuracy', 'Recall'])\n",
        "\n",
        "# take a look at model architecture\n",
        "rnn.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"rnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_44 (Conv2D)          (None, 128, 1292, 64)     640       \n",
            "                                                                 \n",
            " max_pooling2d_44 (MaxPoolin  (None, 64, 646, 64)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 64, 646, 64)       0         \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 64, 646, 128)      73856     \n",
            "                                                                 \n",
            " max_pooling2d_45 (MaxPoolin  (None, 16, 323, 128)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 16, 323, 128)      0         \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 16, 323, 128)      147584    \n",
            "                                                                 \n",
            " max_pooling2d_46 (MaxPoolin  (None, 4, 161, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 4, 161, 128)       0         \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 4, 161, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_47 (MaxPoolin  (None, 1, 80, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 1, 80, 128)        0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 80, 128)           0         \n",
            "                                                                 \n",
            " gru_13 (GRU)                (None, 80, 32)            15552     \n",
            "                                                                 \n",
            " gru_14 (GRU)                (None, 32)                6336      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 391,585\n",
            "Trainable params: 391,585\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tFwQrL5_eRTI",
        "outputId": "dd17b4cb-dacb-4b08-ad74-8fd5d0e57f19"
      },
      "source": [
        "rnn_history = rnn.fit(X_train, y_train, epochs=100, batch_size=100,\n",
        "                  validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "104/104 [==============================] - 1023s 10s/step - loss: 0.6970 - accuracy: 0.5051 - recall: 0.3734 - val_loss: 0.6913 - val_accuracy: 0.5223 - val_recall: 0.2223\n",
            "Epoch 2/100\n",
            "104/104 [==============================] - 991s 10s/step - loss: 0.6932 - accuracy: 0.5156 - recall: 0.3278 - val_loss: 0.6940 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 3/100\n",
            "104/104 [==============================] - 997s 10s/step - loss: 0.6932 - accuracy: 0.5153 - recall: 0.3233 - val_loss: 0.6908 - val_accuracy: 0.5161 - val_recall: 0.0000e+00\n",
            "Epoch 4/100\n",
            "104/104 [==============================] - 998s 10s/step - loss: 0.6906 - accuracy: 0.5260 - recall: 0.4703 - val_loss: 0.6883 - val_accuracy: 0.5289 - val_recall: 0.5945\n",
            "Epoch 5/100\n",
            "104/104 [==============================] - 1022s 10s/step - loss: 0.6881 - accuracy: 0.5328 - recall: 0.4604 - val_loss: 0.6876 - val_accuracy: 0.5317 - val_recall: 0.0792\n",
            "Epoch 6/100\n",
            "104/104 [==============================] - 983s 9s/step - loss: 0.6874 - accuracy: 0.5369 - recall: 0.4985 - val_loss: 0.6875 - val_accuracy: 0.5441 - val_recall: 0.5077\n",
            "Epoch 7/100\n",
            "104/104 [==============================] - 1045s 10s/step - loss: 0.6868 - accuracy: 0.5429 - recall: 0.5147 - val_loss: 0.6863 - val_accuracy: 0.5276 - val_recall: 0.0980\n",
            "Epoch 8/100\n",
            "104/104 [==============================] - 1135s 11s/step - loss: 0.6896 - accuracy: 0.5329 - recall: 0.4561 - val_loss: 0.6909 - val_accuracy: 0.5293 - val_recall: 0.0605\n",
            "Epoch 9/100\n",
            "104/104 [==============================] - 1031s 10s/step - loss: 0.6870 - accuracy: 0.5451 - recall: 0.5216 - val_loss: 0.6830 - val_accuracy: 0.5540 - val_recall: 0.5826\n",
            "Epoch 10/100\n",
            "104/104 [==============================] - 1120s 11s/step - loss: 0.6857 - accuracy: 0.5511 - recall: 0.5634 - val_loss: 0.6826 - val_accuracy: 0.5556 - val_recall: 0.6678\n",
            "Epoch 11/100\n",
            "104/104 [==============================] - 1052s 10s/step - loss: 0.6865 - accuracy: 0.5436 - recall: 0.5370 - val_loss: 0.6810 - val_accuracy: 0.5676 - val_recall: 0.4940\n",
            "Epoch 12/100\n",
            "104/104 [==============================] - 1025s 10s/step - loss: 0.6835 - accuracy: 0.5565 - recall: 0.5471 - val_loss: 0.6790 - val_accuracy: 0.5750 - val_recall: 0.4182\n",
            "Epoch 13/100\n",
            "104/104 [==============================] - 1010s 10s/step - loss: 0.6837 - accuracy: 0.5563 - recall: 0.5350 - val_loss: 0.6851 - val_accuracy: 0.5478 - val_recall: 0.7913\n",
            "Epoch 14/100\n",
            "104/104 [==============================] - 1082s 10s/step - loss: 0.6816 - accuracy: 0.5640 - recall: 0.5475 - val_loss: 0.6784 - val_accuracy: 0.5709 - val_recall: 0.7061\n",
            "Epoch 15/100\n",
            "104/104 [==============================] - 1018s 10s/step - loss: 0.6807 - accuracy: 0.5679 - recall: 0.5550 - val_loss: 0.6771 - val_accuracy: 0.5697 - val_recall: 0.5247\n",
            "Epoch 16/100\n",
            "104/104 [==============================] - 1055s 10s/step - loss: 0.6793 - accuracy: 0.5719 - recall: 0.5479 - val_loss: 0.6834 - val_accuracy: 0.5668 - val_recall: 0.7189\n",
            "Epoch 17/100\n",
            "104/104 [==============================] - 1053s 10s/step - loss: 0.6801 - accuracy: 0.5682 - recall: 0.5755 - val_loss: 0.6785 - val_accuracy: 0.5783 - val_recall: 0.5579\n",
            "Epoch 18/100\n",
            "104/104 [==============================] - 1079s 10s/step - loss: 0.6793 - accuracy: 0.5716 - recall: 0.5473 - val_loss: 0.6931 - val_accuracy: 0.5602 - val_recall: 0.2734\n",
            "Epoch 19/100\n",
            "104/104 [==============================] - 1016s 10s/step - loss: 0.6811 - accuracy: 0.5654 - recall: 0.5664 - val_loss: 0.6843 - val_accuracy: 0.5441 - val_recall: 0.2044\n",
            "Epoch 20/100\n",
            "104/104 [==============================] - 1121s 11s/step - loss: 0.6759 - accuracy: 0.5754 - recall: 0.5668 - val_loss: 0.6764 - val_accuracy: 0.5779 - val_recall: 0.5630\n",
            "Epoch 21/100\n",
            "104/104 [==============================] - 1037s 10s/step - loss: 0.6741 - accuracy: 0.5849 - recall: 0.5790 - val_loss: 0.6796 - val_accuracy: 0.5688 - val_recall: 0.6116\n",
            "Epoch 22/100\n",
            "104/104 [==============================] - 1086s 10s/step - loss: 0.6706 - accuracy: 0.5895 - recall: 0.5919 - val_loss: 0.6898 - val_accuracy: 0.5581 - val_recall: 0.3330\n",
            "Epoch 23/100\n",
            "104/104 [==============================] - 1057s 10s/step - loss: 0.6727 - accuracy: 0.5821 - recall: 0.5759 - val_loss: 0.6797 - val_accuracy: 0.5767 - val_recall: 0.4889\n",
            "Epoch 24/100\n",
            "104/104 [==============================] - 1059s 10s/step - loss: 0.6705 - accuracy: 0.5877 - recall: 0.5875 - val_loss: 0.6753 - val_accuracy: 0.5717 - val_recall: 0.5886\n",
            "Epoch 25/100\n",
            "104/104 [==============================] - 1030s 10s/step - loss: 0.6667 - accuracy: 0.5915 - recall: 0.5982 - val_loss: 0.6816 - val_accuracy: 0.5660 - val_recall: 0.7845\n",
            "Epoch 26/100\n",
            "104/104 [==============================] - 1195s 12s/step - loss: 0.6664 - accuracy: 0.5997 - recall: 0.6082 - val_loss: 0.6820 - val_accuracy: 0.5730 - val_recall: 0.7879\n",
            "Epoch 27/100\n",
            "104/104 [==============================] - 1148s 11s/step - loss: 0.6701 - accuracy: 0.5872 - recall: 0.5970 - val_loss: 0.6792 - val_accuracy: 0.5775 - val_recall: 0.7078\n",
            "Epoch 28/100\n",
            "104/104 [==============================] - 1251s 12s/step - loss: 0.6669 - accuracy: 0.5958 - recall: 0.6006 - val_loss: 0.6959 - val_accuracy: 0.5350 - val_recall: 0.9421\n",
            "Epoch 29/100\n",
            "104/104 [==============================] - 1114s 11s/step - loss: 0.6650 - accuracy: 0.5948 - recall: 0.6084 - val_loss: 0.6758 - val_accuracy: 0.5787 - val_recall: 0.5750\n",
            "Epoch 30/100\n",
            "104/104 [==============================] - 1033s 10s/step - loss: 0.6666 - accuracy: 0.6011 - recall: 0.5899 - val_loss: 0.6716 - val_accuracy: 0.5837 - val_recall: 0.6618\n",
            "Epoch 31/100\n",
            "104/104 [==============================] - 1078s 10s/step - loss: 0.6602 - accuracy: 0.6050 - recall: 0.6307 - val_loss: 0.6779 - val_accuracy: 0.5697 - val_recall: 0.5009\n",
            "Epoch 32/100\n",
            "104/104 [==============================] - 1062s 10s/step - loss: 0.6619 - accuracy: 0.6057 - recall: 0.6124 - val_loss: 0.6719 - val_accuracy: 0.5890 - val_recall: 0.5784\n",
            "Epoch 33/100\n",
            "104/104 [==============================] - 1059s 10s/step - loss: 0.6571 - accuracy: 0.6117 - recall: 0.6183 - val_loss: 0.6811 - val_accuracy: 0.5763 - val_recall: 0.4344\n",
            "Epoch 34/100\n",
            "104/104 [==============================] - 1002s 10s/step - loss: 0.6589 - accuracy: 0.6089 - recall: 0.6211 - val_loss: 0.6722 - val_accuracy: 0.5738 - val_recall: 0.5562\n",
            "Epoch 35/100\n",
            "104/104 [==============================] - 1040s 10s/step - loss: 0.6534 - accuracy: 0.6156 - recall: 0.6207 - val_loss: 0.6944 - val_accuracy: 0.5635 - val_recall: 0.8262\n",
            "Epoch 36/100\n",
            "104/104 [==============================] - 1042s 10s/step - loss: 0.6548 - accuracy: 0.6144 - recall: 0.6319 - val_loss: 0.6759 - val_accuracy: 0.5816 - val_recall: 0.5111\n",
            "Epoch 37/100\n",
            " 67/104 [==================>...........] - ETA: 5:59 - loss: 0.6467 - accuracy: 0.6282 - recall: 0.6118"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "5as9F8IjjEX1",
        "outputId": "f628178b-e995-4c17-fc3b-0df1b8fea42f"
      },
      "source": [
        " visualize_training_results(rnn_history)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f1a5f6b2da43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_training_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'visualize_training_results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zeo-n7GYF8H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}